## Команда Atomic ML:
 - ML Сухарев Фёдор
 - ML Тенчурин Артемий
 - Web Дудукин Матвей

## Основные ссылки:
 - [Решение на google drive](https://drive.google.com/drive/folders/1cFbbdqjZuUc74jInjJrsB2fwivZJb-VE) 
 - Сайт [artnn.space](http://artnn.space)
 - [Изображения сайта](https://drive.google.com/drive/folders/1vco2jT6tuTXUK-7DNczDp4o2yryRMRjE?usp=share_link)
 - [Google notebook с описанием решения](https://colab.research.google.com/drive/1OkSg1g-aP6wLo-_VbNY7N76SEk6sQfX5?usp=sharing)
## Описание задачи

- **Цель**: автоматический анализ тональности текстовых отзывов (определение класса тональности для каждого отзыва).
- **Зачем заказчику**: снижение нагрузки на модераторов, единые критерии оценки тональности, мониторинг настроения клиентов по источникам.
- **Вход**: текст отзыва и источник.
- **Выход**: класс тональности и качество по метрике F1.

---

## Структура репозитория и установка

### Установка
#### Предварительные требования

Перед началом работы убедитесь, что у вас установлены:
- **Python** >= 3.12
- **Node.js**: latest

### Установка зависимостей

#### Основные библиотеки Python
Проект требует следующие версии пакетов (указаны минимальные версии):

```text
numpy>=2.1.0
torch>=2.6.0
pandas>=2.2.3
transformers>=4.46.0
scikit-learn>=1.5.2
matplotlib>=3.9.2
seaborn>=0.13.2
fastapi>=0.115.0
uvicorn[standard]>=0.30.0
python-multipart>=0.0.9
Pillow>=11.0.0
```

### Пошаговая инструкция

### 1. Клонирование репозитория
Склонируйте проект с GitHub на локальную машину:

```bash
git clone https://github.com/rodmandf/Atomic-ML-Hack-28.11.25
cd Atomic-ML-Hack-28.11.25
```

### 2. Загрузка весов моделей
Для корректной работы ML-модуля необходимо скачать обученную модель.

1. Скачайте архив с моделью по ссылке: [Google Drive](https://drive.google.com/drive/folders/1sllYMN8UCMdJfStvp60oH-Ng1Yh5A5I1?usp=sharing)
2. Разархивируйте и перенсите содержимое в папку `models` в корне проекта. (папку cointegrated_ART перенести в models/)

### 3. Настройка и запуск Backend
Откройте терминал и выполните следующие команды для запуска серверной части:

```bash
cd backend
# Рекомендуется использовать виртуальное окружение (venv/conda)
pip install -r requirements.txt
python server.py
```
*Сервер запустится и будет ожидать запросы (обычно по адресу http://localhost:8000).*

### 4. Настройка и запуск Frontend
Откройте **новый** терминал (не закрывая терминал с бэкендом) и выполните:

```bash
cd frontend
npm install
npm run dev
```
*После сборки интерфейс будет доступен в браузере (обычно http://localhost:5173 или http://localhost:3000, см. вывод в консоли).*


### Основные директории github

- **`/backend`**
  - **Назначение**: API-сервис для обработки текстовых запросов.
  - **Технологии**: Python (FastAPI/Flask).
  - **Функционал**:
    - Прием текстовых обращений или пакетная загрузка файлов (CSV/XLSX).
    - Препроцессинг текста (очистка, токенизация).
    - Очереди задач для обработки больших массивов отзывов.
    - Маршруты для интеграции с ML-модулем (классификация: *Позитив/Негатив/Нейтрально*).

- **`/frontend`**
  - **Назначение**: Дашборд для аналитиков и сотрудников ведомств.
  - **Функционал**:
    - Визуализация статистики: графики распределения тональности, вывод всех метрик по классам и их усреднения.
    - Бизнес метрика.

- **`/ml_training`**
  - **Назначение**: Обучение NLP-моделей.
  - **Содержимое**:
    - Дообучение (Fine-tuning) языковых моделей (на базе RuBERT, e.g., `rubert-tiny2`, `cointegrated`).
    - Пайплайны валидации качества на размеченных данных Правительства Москвы.
    - Эксперименты с различными архитектурами трансформеров.

- **`/models`**
  - **Назначение**: Рабочие модели.
  - **Содержимое**:
    - Веса обученных нейросетей (HuggingFace format / ONNX).
    - Токенизаторы и конфигурационные файлы (`config.json`).

- **`/data`**
  - **Назначение**: Хранилище данных.
  - **Содержимое**:
    - Сырые данные (Raw Datasets).
    - Размеченный датасет для дообучения.
    - Файлы с результатами скоринга, содержащие предсказанные метки классов.
- **`/report`**
  - **Назначение**: Статистика по датасетам.
  - **Содержимое**:
    - JSON и PNG файлы для визуализации на сайте

- **`inference.ipynb`**
  - Файл для предсказания модели
  - Выводит метрику и новый .csv файл

---

## 1. Анализ данных

### Проблемы качества данных

В ходе исследовательского анализа данных выявлены:
- неустойчивые метки (часть разметки перепутана);
- странные комментарии (сарказм, спам, тексты вне тематики).

### Вывод

- Присутствует заметный шум, поэтому даже идеальная модель ограничена качеством разметки.
- Часть ошибок моделей объясняется именно качеством исходных данных.

---

## 2. Базовое решение (baseline)

### Модель

Готовый sentiment-классификатор `seara/rubert-tiny2-russian-sentiment`, без дообучения и без предобработки текстов.

### Подход

- Загружаем сырые отзывы.
- Подаём их в модель через `AutoModelForSequenceClassification` из библиотеки `transformers`.
- Считаем F1 на валидационной выборке.

### Результат

- **F1 ≈ 0.705** на наших данных.

### Вывод

- Готовая модель даёт разумное стартовое качество.
- Это baseline, с которым сравниваются все остальные решения.

---

## 3. Модель с максимальным качеством (RuBERT base)

### Идея

Использовать более мощную модель `cointegrated/rubert-base`, дообучив её на наших данных.

### Эксперимент

- Fine-tune последних 9 из 12 слоёв базовой модели на сырых данных.
- Разбиение на обучающую и валидационную выборку: train/test split 0.9.
- Используется стандартный классификатор на базе `AutoModelForSequenceClassification`.

### Результат

- **F1 на валидации ≈ 0.775**.
- **Время инференса**: около 15 минут на 10 000 строк (Google Colab, GPU Nvidia T4 / RTX 4050 Laptop).

### Вывод

- Качество заметно выше baseline.
- Однако скорость инференса недостаточна для практического использования на больших объёмах данных.

---

## 4. Ускорение за счёт лёгкой модели (RuBERT tiny2 без предобработки)

### Идея

Сохранить приемлемое качество, но сильно сократить время инференса за счёт более компактной модели.

### Эксперимент

Обучение `cointegrated/rubert-tiny2` на сырых, неочищенных данных.

### Результат

- **F1 ≈ 0.7363** на валидации.
- Инференс существенно быстрее, чем у `rubert-base`.

### Вывод

- Найден компромисс: модель быстрее, чем `rubert-base`, и качественнее исходного baseline.
- Остаётся потенциал улучшения за счёт работы с данными.

---

## 5. Предобработка данных и улучшение tiny2

### Цель

Улучшить входные данные, не усложняя архитектуру модели.

### Выполненная предобработка (ноутбук `EDA_new.ipynb`)

- Очистка текста от повторяющихся знаков препинания и лишнего "шума".
- Приведение текста к нижнему регистру.
- Добавление источника в начало текста в формате: `[SRC] источник [TEXT] текст`, для явной семантической связи между источником и содержанием отзыва.

### Эксперимент

Обучение `cointegrated/rubert-tiny2` на предобработанных данных (очищенный текст + тег источника).

### Результат

- **F1 ≈ 0.7475** на валидации.
- **Время инференса**:
  - около 2 минут на 10 000 строк;
  - около 10 минут на 200 000 строк;
  - тесты проводились на Nvidia T4 (Google Colab) и RTX 4050 Laptop.

### Вывод

- Удалось сохранить высокую скорость.
- Качество улучшилось по сравнению с `tiny2` на сырых данных.

---

## Сравнение вариантов

| Вариант                              | Модель                               | Данные                           | F1      | Время инференса (10k строк) |
|--------------------------------------|--------------------------------------|----------------------------------|---------|------------------------------|
| 1. Baseline                          | `seara/rubert-tiny2-sentiment`       | сырые                            | ≈ 0.705 | —                            |
| 2. Максимальное качество             | `cointegrated/rubert-base`           | сырые                            | ≈ 0.775 | ~15 мин                      |
| 3. Быстрая модель без предобработки  | `cointegrated/rubert-tiny2`          | сырые                            | 0.7363  | ~2 мин                       |
| 4. Итоговая модель (выбор)           | `cointegrated/rubert-tiny2`          | предобработанные + тег источника | 0.7475  | ~2 мин                       |
