# Atomic ML
## ML Сухарев Фёдор
## ML Тенчурин Артемий
## Web Дудукин Матвей

## Описание задачи

- **Цель**: автоматический анализ тональности текстовых отзывов (определение класса тональности для каждого отзыва).
- **Зачем заказчику**: снижение нагрузки на модераторов, единые критерии оценки тональности, мониторинг настроения клиентов по источникам.
- **Вход**: текст отзыва и источник.
- **Выход**: класс тональности и качество по метрике F1.

---

## 1. Анализ данных

### Проблемы качества данных

В ходе исследовательского анализа данных выявлены:
- неустойчивые метки (часть разметки перепутана);
- странные комментарии (сарказм, спам, тексты вне тематики).

### Вывод

- Присутствует заметный шум, поэтому даже идеальная модель ограничена качеством разметки.
- Часть ошибок моделей объясняется именно качеством исходных данных.

---

## 2. Базовое решение (baseline)

### Модель

Готовый sentiment-классификатор `seara/rubert-tiny2-russian-sentiment`, без дообучения и без предобработки текстов.

### Подход

- Загружаем сырые отзывы.
- Подаём их в модель через `AutoModelForSequenceClassification` из библиотеки `transformers`.
- Считаем F1 на валидационной выборке.

### Результат

- **F1 ≈ 0.705** на наших данных.

### Вывод

- Готовая модель даёт разумное стартовое качество.
- Это baseline, с которым сравниваются все остальные решения.

---

## 3. Модель с максимальным качеством (RuBERT base)

### Идея

Использовать более мощную модель `cointegrated/rubert-base`, дообучив её на наших данных.

### Эксперимент

- Fine-tune последних 9 из 12 слоёв базовой модели на сырых данных.
- Разбиение на обучающую и валидационную выборку: train/test split 0.9.
- Используется стандартный классификатор на базе `AutoModelForSequenceClassification`.

### Результат

- **F1 на валидации ≈ 0.775**.
- **Время инференса**: около 15 минут на 10 000 строк (Google Colab, GPU Nvidia T4 / RTX 4050 Laptop).

### Вывод

- Качество заметно выше baseline.
- Однако скорость инференса недостаточна для практического использования на больших объёмах данных.

---

## 4. Ускорение за счёт лёгкой модели (RuBERT tiny2 без предобработки)

### Идея

Сохранить приемлемое качество, но сильно сократить время инференса за счёт более компактной модели.

### Эксперимент

Обучение `cointegrated/rubert-tiny2` на сырых, неочищенных данных.

### Результат

- **F1 ≈ 0.7363** на валидации.
- Инференс существенно быстрее, чем у `rubert-base`.

### Вывод

- Найден компромисс: модель быстрее, чем `rubert-base`, и качественнее исходного baseline.
- Остаётся потенциал улучшения за счёт работы с данными.

---

## 5. Предобработка данных и улучшение tiny2

### Цель

Улучшить входные данные, не усложняя архитектуру модели.

### Выполненная предобработка (ноутбук `EDA_new.ipynb`)

- Очистка текста от повторяющихся знаков препинания и лишнего "шума".
- Приведение текста к нижнему регистру.
- Добавление источника в начало текста в формате: `[SRC] источник [TEXT] текст`, для явной семантической связи между источником и содержанием отзыва.

### Эксперимент

Обучение `cointegrated/rubert-tiny2` на предобработанных данных (очищенный текст + тег источника).

### Результат

- **F1 ≈ 0.7475** на валидации.
- **Время инференса**:
  - около 2 минут на 10 000 строк;
  - около 10 минут на 200 000 строк;
  - тесты проводились на Nvidia T4 (Google Colab) и RTX 4050 Laptop.

### Вывод

- Удалось сохранить высокую скорость.
- Качество улучшилось по сравнению с `tiny2` на сырых данных.

---

## Сравнение вариантов

| Вариант                              | Модель                               | Данные                           | F1      | Время инференса (10k строк) |
|--------------------------------------|--------------------------------------|----------------------------------|---------|------------------------------|
| 1. Baseline                          | `seara/rubert-tiny2-sentiment`       | сырые                            | ≈ 0.705 | —                            |
| 2. Максимальное качество             | `cointegrated/rubert-base`           | сырые                            | ≈ 0.775 | ~15 мин                      |
| 3. Быстрая модель без предобработки  | `cointegrated/rubert-tiny2`          | сырые                            | 0.7363  | быстрее base                 |
| 4. Итоговая модель (выбор)           | `cointegrated/rubert-tiny2`          | предобработанные + тег источника | 0.7475  | ~2 мин                       |

---

## Итоговый выбор

### Выбранная модель

`cointegrated/rubert-tiny2`, обученная на предобработанных данных с добавленным тегом источника.

### Причины выбора

- Качество F1 выше, чем у baseline и `tiny2` без предобработки.
- Скорость инференса в десятки раз лучше, чем у `rubert-base`, что критично при больших объёмах отзывов.
- Архитектура остаётся достаточно лёгкой для развёртывания в производственной среде.

### Что это даст бизнесу

- Обработка больших объёмов отзывов за приемлемое время.
- Более точное разделение позитивных/негативных отзывов.
- Возможность быстро находить проблемные отзывы по источникам.
