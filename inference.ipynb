{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"vOJfQGtrM71F"},"outputs":[],"source":["import os\n","import torch\n","import pandas as pd\n","import numpy as np\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification\n","from sklearn.metrics import f1_score\n","from tqdm import tqdm\n","import re\n","import unicodedata"]},{"cell_type":"markdown","source":["### Доп функции предобработки:"],"metadata":{"id":"wTSRfZ-EHQR1"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"zxSURUDpFTu9"},"outputs":[],"source":["def clean_text(text):\n","    \"\"\"Очистка текста\"\"\"\n","\n","    # Проверка на NaN/None\n","    if not isinstance(text, str):\n","        return \"\"\n","\n","    # 1. Нижний регистр\n","    text = text.lower()\n","\n","    # 2. Удаление эмодзи и спец символов (оставляем буквы, цифры, пунктуацию, пробелы)\n","    cleaned = []\n","    for char in text:\n","        category = unicodedata.category(char)\n","        if category[0] in ['L', 'N', 'P', 'Z']:\n","            cleaned.append(char)\n","    text = ''.join(cleaned)\n","\n","    # 3. Защита многоточия\n","    text = text.replace('...', '__ELLIPSIS__')\n","\n","    # 4. Уменьшение повторяющихся знаков до одного\n","    text = re.sub(r'([!?;:,\\-—–])\\1+', r'\\1', text)\n","\n","    # 5. Восстановление многоточия\n","    text = text.replace('__ELLIPSIS__', '...')\n","\n","    # 6. Удаление лишних пробелов\n","    text = re.sub(r'\\s{2,}', ' ', text)\n","\n","    # 7. Удаление пробелов в начале/конце\n","    text = text.strip()\n","\n","    return text\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TqRU591bFTu-"},"outputs":[],"source":["def combine_text_with_src(df, text_col='text', src_col='src', output_col='text'):\n","    \"\"\"\n","    Склеивает текст из двух столбцов по шаблону:\n","    [SRC] текст из source [TEXT] текст из text\n","\n","    Args:\n","        df (pd.DataFrame): Исходный датафрейм\n","        text_col (str): Имя столбца с текстом\n","        src_col (str): Имя столбца с источником\n","        output_col (str): Имя выходного столбца\n","\n","    Returns:\n","        pd.DataFrame: DataFrame с новым столбцом\n","    \"\"\"\n","\n","    # Проверка наличия столбцов\n","    if text_col not in df.columns:\n","        raise ValueError(f\"Столбец '{text_col}' не найден\")\n","    if src_col not in df.columns:\n","        raise ValueError(f\"Столбец '{src_col}' не найден\")\n","\n","    # Склеиваем строки\n","    df[output_col] = \"[SRC] \" + df[src_col].astype(str) + \" [TEXT] \" + df[text_col].astype(str)\n","\n","    return df\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TuYjVLtnFTu-"},"outputs":[],"source":["def print_token_stats(lengths):\n","    print(f\"Минимальное количество токенов: {np.min(lengths)}\")\n","    print(f\"Максимальное количество токенов: {np.max(lengths)}\")\n","    print(f\"Среднее количество токенов: {np.mean(lengths):.2f}\")\n","    print(f\"Медиана количества токенов: {np.median(lengths):.2f}\")\n","    print(f\"Стандартное отклонение: {np.std(lengths):.2f}\")\n","    print(f\"25-й перцентиль: {np.percentile(lengths, 25):.2f}\")\n","    print(f\"75-й перцентиль: {np.percentile(lengths, 75):.2f}\")\n","    print(f\"Общее количество комментариев: {len(lengths)}\")\n"]},{"cell_type":"markdown","source":["### Основной пайплайн"],"metadata":{"id":"GBxvbqRXHUJ9"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PX39WEpDS866","executionInfo":{"status":"ok","timestamp":1764414600972,"user_tz":-180,"elapsed":21016,"user":{"displayName":"Artnn","userId":"15959169787588878692"}},"outputId":"f3bfdece-516e-426d-8144-a23ca99e5115"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["MODEL_DIR = \"/content/drive/MyDrive/Colab Notebooks/Hack_28-11-2025/models/cointegrated_ART\"\n","\n","BASE_MODEL_NAME = \"ai-forever/ruBert-base\""],"metadata":{"id":"NumNawO9NHby"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Inference device: {device}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LlNDThASNNra","executionInfo":{"status":"ok","timestamp":1764414601030,"user_tz":-180,"elapsed":9,"user":{"displayName":"Artnn","userId":"15959169787588878692"}},"outputId":"bb9a8c4d-fe67-41d1-e7b3-17e89b6ab389"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Inference device: cuda\n"]}]},{"cell_type":"code","source":["try:\n","    tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR)\n","    print(\"Tokenizer loaded from local folder.\")\n","except Exception as e:\n","    print(f\"Warning: Local tokenizer failed ({e}). Loading from HuggingFace Hub\")\n","    tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_NAME)"],"metadata":{"collapsed":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"uXGMRpR0NWLy","executionInfo":{"status":"ok","timestamp":1764414606006,"user_tz":-180,"elapsed":4975,"user":{"displayName":"Artnn","userId":"15959169787588878692"}},"outputId":"96223e2a-8b16-4861-9930-518f121e53d3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Tokenizer loaded from local folder.\n"]}]},{"cell_type":"code","source":["try:\n","    model = AutoModelForSequenceClassification.from_pretrained(MODEL_DIR)\n","    model.to(device)\n","    model.eval()\n","    print(\"Model loaded successfully.\")\n","except Exception as e:\n","    raise RuntimeError(f\"Could not load model from {MODEL_DIR}. Error: {e}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sNXl2LX_NcZh","executionInfo":{"status":"ok","timestamp":1764414629102,"user_tz":-180,"elapsed":21229,"user":{"displayName":"Artnn","userId":"15959169787588878692"}},"outputId":"d03b3731-345f-4514-dcdf-ad2d5dadc833"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model loaded successfully.\n"]}]},{"cell_type":"code","source":["id2label = {0: \"neutral\", 1: \"positive\", 2: \"negative\"}"],"metadata":{"id":"rb-d1fAbN6m6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def process_and_predict(input_csv_path: str, output_csv_path: str):\n","    \"\"\"\n","    Принимает путь к входному CSV, делает предсказания, сохраняет результат.\n","    Возвращает: (metric_f1, output_path)\n","    \"\"\"\n","\n","    if not os.path.exists(input_csv_path):\n","        raise FileNotFoundError(f\"Input file not found: {input_csv_path}\")\n","\n","    try:\n","        df = pd.read_csv(input_csv_path)\n","    except:\n","        df = pd.read_csv(input_csv_path, sep=';')\n","\n","    if 'text' not in df.columns:\n","        raise ValueError(\"CSV must contain a 'text' column!\")\n","\n","    # Очистка от NaN\n","    df['text'] = df['text'].fillna(\"\")\n","    df['text'] = df['text'].apply(clean_text)\n","\n","    if 'src' in df.columns:\n","        df = combine_text_with_src(df, text_col='text', src_col='src', output_col='text')\n","        inference_column = 'text'\n","    else:\n","        inference_column = 'text'\n","\n","    # Берем готовый список текстов\n","    texts = df[inference_column].tolist()\n","    # Инференс (батчами)\n","    batch_size = 32\n","    predictions = []\n","\n","    print(f\"Predicting for {len(texts)} texts\")\n","\n","    for i in tqdm(range(0, len(texts), batch_size)):\n","        batch_texts = texts[i : i + batch_size]\n","\n","        # Токенизация\n","        inputs = tokenizer(\n","            batch_texts,\n","            return_tensors=\"pt\",\n","            truncation=True,\n","            padding=True,\n","            max_length=512\n","        ).to(device)\n","\n","        # Предикт\n","        with torch.no_grad():\n","            logits = model(**inputs).logits\n","            preds = torch.argmax(logits, dim=-1).cpu().numpy()\n","\n","        predictions.extend(preds)\n","\n","\n","    df['predicted_label'] = predictions\n","\n","\n","    # Считаем метрику (если есть истинные метки)\n","    f1_macro = None\n","    if 'label' in df.columns:\n","        try:\n","            true_labels = df['label'].astype(int).tolist()\n","            f1_macro = f1_score(true_labels, predictions, average='macro')\n","            print(f\"Validation Macro-F1: {f1_macro:.4f}\")\n","        except Exception as e:\n","            print(f\"Metric calculation skipped: {e}\")\n","\n","    # Сохраняем\n","    # Создаем папку для вывода, если нет\n","    os.makedirs(os.path.dirname(output_csv_path), exist_ok=True)\n","\n","    df.to_csv(output_csv_path, index=False)\n","    print(f\"Saved results to: {output_csv_path}\")\n","\n","    return f1_macro, output_csv_path"],"metadata":{"id":"CWCx9hxSOCUy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","    TEST_FILE = \"/content/drive/MyDrive/Colab Notebooks/Hack_28-11-2025/data/raw/test.csv\"\n","    RESULT_FILE = \"/content/drive/MyDrive/Colab Notebooks/Hack_28-11-2025/data/processed/new_test_predictions.csv\"\n","\n","    if os.path.exists(TEST_FILE):\n","        metric, out_path = process_and_predict(TEST_FILE, RESULT_FILE)\n","        print(f\"Result saved to: {out_path}\")\n","        print(f\"Metric: {metric}\")\n","    else:\n","        print(f\"Test file '{TEST_FILE}' not found. Skipping check.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U_G2w9j7RQk6","executionInfo":{"status":"ok","timestamp":1764414728790,"user_tz":-180,"elapsed":92636,"user":{"displayName":"Artnn","userId":"15959169787588878692"}},"outputId":"7742be5e-1230-45e2-a113-85b5850cd7bd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Predicting for 58092 texts\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1816/1816 [01:23<00:00, 21.71it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Saved results to: /content/drive/MyDrive/Colab Notebooks/Hack_28-11-2025/data/processed/new_test_predictions.csv\n","Result saved to: /content/drive/MyDrive/Colab Notebooks/Hack_28-11-2025/data/processed/new_test_predictions.csv\n","Metric: None\n"]}]}]}